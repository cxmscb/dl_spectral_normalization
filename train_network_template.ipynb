{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from dl_spectral_normalization import dl_utils\n",
    "from dl_spectral_normalization import adversarial as ad\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "We provide the code for downloading and loading one of three types of datasets:\n",
    "- CIFAR10\n",
    "- MNIST\n",
    "- SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10\n",
    "from get_cifar10 import get_cifar10_dataset\n",
    "Xtr, Ytr, Xtt, Ytt = get_cifar10_dataset(0, n_samps=50000)\n",
    "val_set = {'X': Xtt[:500], 'Y': Ytt[:500]}\n",
    "Xtt, Ytt = Xtt[500:], Ytt[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# NOTE: If you use MNIST, a lot of the dl_spectral_normalization functions \n",
    "# will require you to set num_channels=1\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "Xtr = mnist.train.images.reshape(-1, 28, 28, 1)\n",
    "Ytr = mnist.train.labels.astype(float)\n",
    "Xtt = mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "Ytt = mnist.test.labels.astype(float)\n",
    "val_set = {'X': Xtt[:500], 'Y': Ytt[:500]}\n",
    "Xtt, Ytt = Xtt[500:], Ytt[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVHN\n",
    "from get_cifar10 import get_svhn_dataset\n",
    "Xtr, Ytr, Xtt, Ytt = get_svhn_dataset(0)\n",
    "val_set = {'X': Xtt[:500], 'Y': Ytt[:500]}\n",
    "Xtt, Ytt = Xtt[500:], Ytt[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select network\n",
    "\n",
    "Please see `spectral_adversarial_regularization/models` for the full list of models provided. We give examples of networks trained in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_spectral_normalization.models import alexnet as model\n",
    "arch = model.alexnet_sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(Xtr, Ytr, val_set, arch, save_dir, \n",
    "                  beta=1,\n",
    "                  adv=None, order=2, eps=0.3,\n",
    "                  opt='momentum', lr_initial=0.01,\n",
    "                  num_epochs=200, save_every=25,\n",
    "                  gpu_prop=0.3, retrain=False):\n",
    "    \"\"\"\n",
    "    Wrapper for training a network using dl_spectral_normalization\n",
    "    \n",
    "    Inputs\n",
    "    ----------------------------------------------------------------------\n",
    "        Xtr:           Training data (channels last format)\n",
    "        Ytr:           Training labels (not one-hot encoded)\n",
    "        val_set:       Dict with keys 'X' and 'Y' for the validation\n",
    "                       data and labels\n",
    "        arch:          One of the architectures from\n",
    "                       dl_spectral_normalization/models\n",
    "        save_dir:      Directory to save weights and TensorBoard logs\n",
    "        beta:          Amount of spectral normalization (max spectral \n",
    "                       norm of a layer). Use beta=np.inf for no\n",
    "                       spectral normalization\n",
    "        adv:           Adversarial training scheme: 'erm', 'fgm', \n",
    "                       'pgm', or 'wrm'\n",
    "        order:         Order of attack (np.inf, 1, or 2) for FGM or PGM\n",
    "        eps:           Magnitude of attack during training\n",
    "        opt:           Optimizer type ('adam' or 'momentum')\n",
    "        lr_initial:    Initial learning rate\n",
    "        num_epochs:    Number of epochs to train for\n",
    "        save_every:    Save weights every this many epochs\n",
    "        gpu_prop:      Proportion of GPU to allocate for training process\n",
    "        retrain:       Whether or not to delete the existing weights and\n",
    "                       retrain the network\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.isdir(save_dir): \n",
    "        if retrain: os.system('rm -rf %s'%(save_dir))\n",
    "        else: return\n",
    "\n",
    "    print('eps = %.4f, saving weights to %s'%(eps, save_dir))\n",
    "    _ = dl_utils.build_graph_and_train(Xtr, Ytr, save_dir, arch,\n",
    "                                       val_set=val_set,\n",
    "                                       num_channels=Xtr.shape[-1],\n",
    "                                       beta=beta,\n",
    "                                       adv=adv, order=order, eps=eps,\n",
    "                                       opt=opt, lr_initial=lr_initial,\n",
    "                                       num_epochs=num_epochs, save_every=save_every,\n",
    "                                       gpu_prop=gpu_prop, \n",
    "                                       batch_size=128,\n",
    "                                       early_stop_acc=0.999,\n",
    "                                       early_stop_acc_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory in which we save weights\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/alexnet/'\n",
    "\n",
    "# List of betas to sweep through (np.inf means no spectral normalization)\n",
    "beta_list = np.array([np.inf, 1.0, 1.3, 1.6, 2.0, 4.0])\n",
    "\n",
    "# Specify the amount of perturbation to use during training\n",
    "C2 = np.mean([np.sqrt(np.sum(np.square(i))) for i in Xtr])\n",
    "gamma = 0.002*C2 # for MNIST, use 0.04*C2\n",
    "eps_wrm = 1./(2*gamma)\n",
    "eps = 0.05*C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERM\n",
    "for beta in beta_list:\n",
    "    save_dir = os.path.join(dirname, 'erm_beta%s'%(beta))\n",
    "    train_network(Xtr, Ytr, val_set, arch, save_dir, adv='erm', beta=beta)\n",
    "    \n",
    "# FGM\n",
    "for beta in beta_list:\n",
    "    save_dir = os.path.join(dirname, 'fgm_beta%s'%(beta))\n",
    "    train_network(Xtr, Ytr, val_set, arch, save_dir, adv='fgm', beta=beta, eps=eps)\n",
    "    \n",
    "# PGM\n",
    "for beta in beta_list:\n",
    "    save_dir = os.path.join(dirname, 'pgm_beta%s'%(beta))\n",
    "    train_network(Xtr, Ytr, val_set, arch, save_dir, adv='pgm', beta=beta, eps=eps)\n",
    "    \n",
    "# WRM\n",
    "for beta in beta_list:\n",
    "    save_dir = os.path.join(dirname, 'wrm_beta%s'%(beta))\n",
    "    train_network(Xtr, Ytr, val_set, arch, save_dir, adv='wrm', beta=beta, eps=eps_wrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test trained networks with various-magnitude attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adv_attack_curves(X, Y, arch, eps_list, defense, attack, resultsfile, beta_list, dirname,\n",
    "                               load_epoch=None, num_channels=3, order=2, opt='momentum'):\n",
    "    if os.path.isfile(resultsfile):\n",
    "        adv_results = pickle.load(file(resultsfile, 'rb'))\n",
    "    else:\n",
    "        adv_results = {}\n",
    "        \n",
    "    for beta in beta_list:\n",
    "        if beta in adv_results: continue\n",
    "        save_dir = os.path.join(dirname, '%s_beta%s'%(defense, beta))\n",
    "        \n",
    "        adv_accs = np.zeros(len(eps_list))\n",
    "        for i, eps in enumerate(eps_list):\n",
    "            adv_accs[i] = ad.test_net_against_adv_examples(X, Y, save_dir, arch, \n",
    "                                                           beta=beta, method=attack,\n",
    "                                                           load_epoch=load_epoch,\n",
    "                                                           num_channels=num_channels,\n",
    "                                                           order=order,\n",
    "                                                           opt=opt)\n",
    "        adv_results[beta] = adv_accs\n",
    "        pickle.dump(adv_results, file(resultsfile, 'wb'))\n",
    "        \n",
    "    return adv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eps attack values to sweep over\n",
    "eps_list = np.linspace(0, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfile = os.path.join(dirname, 'erm_defense_pgm_attacks_testset.pickle')\n",
    "adv_results = generate_adv_attack_curves(Xtt, Ytt, arch, eps_list, 'erm', ad.pgm,\n",
    "                                         resultsfile, beta_list, dirname)\n",
    "\n",
    "resultsfile = os.path.join(dirname, 'fgm_defense_fgm_attacks_testset.pickle')\n",
    "adv_results = generate_adv_attack_curves(Xtt, Ytt, arch, eps_list, 'fgm', ad.fgm,\n",
    "                                         resultsfile, beta_list, dirname)\n",
    "\n",
    "resultsfile = os.path.join(dirname, 'pgm_defense_pgm_attacks_testset.pickle')\n",
    "adv_results = generate_adv_attack_curves(Xtt, Ytt, arch, eps_list, 'pgm', ad.pgm,\n",
    "                                         resultsfile, beta_list, dirname)\n",
    "\n",
    "resultsfile = os.path.join(dirname, 'wrm_defense_wrm_attacks_testset.pickle')\n",
    "adv_results = generate_adv_attack_curves(Xtt, Ytt, arch, eps_list, 'wrm', ad.wrm,\n",
    "                                         resultsfile, beta_list, dirname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
