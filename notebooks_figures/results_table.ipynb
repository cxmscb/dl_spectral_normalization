{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from analysis import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../') \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_cifar10 import get_cifar10_dataset\n",
    "\n",
    "Xtr, Ytr, Xtt, Ytt = get_cifar10_dataset(0, n_samps=50000)\n",
    "Xva, Yva = Xtt[:500], Ytt[:500]\n",
    "Xtt, Ytt = Xtt[500:], Ytt[500:]\n",
    "C2 = np.mean([np.sqrt(np.sum(np.square(i))) for i in Xtr])\n",
    "gamma = 0.002*C2\n",
    "eps_wrm = 1./(2*gamma)\n",
    "eps = 0.05*C2\n",
    "\n",
    "attacks_dict = {\n",
    "    'erm': 0,\n",
    "    'fgm': eps,\n",
    "    'pgm': eps,\n",
    "    'wrm': eps_wrm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.7620\ttest acc 0.7889\n",
      "beta = 2.0:\ttrain acc 0.9980\tvalidation acc 0.8140\ttest acc 0.7898\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9999\tvalidation acc 0.5960\ttest acc 0.6113\n",
      "beta = 1.3:\ttrain acc 0.7564\tvalidation acc 0.6120\ttest acc 0.6523\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9854\tvalidation acc 0.4820\ttest acc 0.5043\n",
      "beta = 1.6:\ttrain acc 0.9170\tvalidation acc 0.5980\ttest acc 0.6159\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9831\tvalidation acc 0.5320\ttest acc 0.5441\n",
      "beta = 1.6:\ttrain acc 0.9318\tvalidation acc 0.6180\ttest acc 0.6283\n"
     ]
    }
   ],
   "source": [
    "# AlexNet\n",
    "from dl_spectral_normalization.models import alexnet as model\n",
    "arch = model.alexnet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_alexnet.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/alexnet/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.4700\ttest acc 0.5060\n",
      "beta = 1.3:\ttrain acc 0.6682\tvalidation acc 0.5640\ttest acc 0.5597\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9871\tvalidation acc 0.4260\ttest acc 0.4379\n",
      "beta = 1.6:\ttrain acc 0.8605\tvalidation acc 0.5220\ttest acc 0.5416\n"
     ]
    }
   ],
   "source": [
    "# AlexNet norm-inf attacks (eps=0.1)\n",
    "from dl_spectral_normalization.models import alexnet as model\n",
    "attacks_dict_orderinf = {\n",
    "    'fgm': 0.1,\n",
    "    'pgm': 0.1\n",
    "}\n",
    "arch = model.alexnet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_alexnet_orderinf_eps0.1.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/alexnet_norminfattacks_eps0.1/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict_orderinf, results_file, dirname, order=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9932\tvalidation acc 0.5500\ttest acc 0.5846\n",
      "beta = 1.3:\ttrain acc 0.8141\tvalidation acc 0.6740\ttest acc 0.6731\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.5081\tvalidation acc 0.2140\ttest acc 0.2088\n",
      "beta = 1.3:\ttrain acc 0.3711\tvalidation acc 0.3520\ttest acc 0.3041\n"
     ]
    }
   ],
   "source": [
    "# AlexNet norm-inf attacks (eps=0.3)\n",
    "from dl_spectral_normalization.models import alexnet as model\n",
    "attacks_dict_orderinf = {\n",
    "    'fgm': 0.3,\n",
    "    'pgm': 0.3\n",
    "}\n",
    "arch = model.alexnet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_alexnet_orderinf_eps0.3.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/alexnet_norminfattacks_eps0.3/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict_orderinf, results_file, dirname, order=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.7700\ttest acc 0.7919\n",
      "beta = 2.0:\ttrain acc 0.9997\tvalidation acc 0.7820\ttest acc 0.7892\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9992\tvalidation acc 0.5580\ttest acc 0.5960\n",
      "beta = 4.0:\ttrain acc 1.0000\tvalidation acc 0.6020\ttest acc 0.5986\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9808\tvalidation acc 0.5280\ttest acc 0.5263\n",
      "beta = 1.6:\ttrain acc 0.8830\tvalidation acc 0.5800\ttest acc 0.6069\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9659\tvalidation acc 0.5080\ttest acc 0.5223\n",
      "beta = 1.3:\ttrain acc 0.6812\tvalidation acc 0.5820\ttest acc 0.6025\n"
     ]
    }
   ],
   "source": [
    "# AlexNet elu\n",
    "from dl_spectral_normalization.models import alexnet as model\n",
    "arch = model.alexnet_elu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_alexnet_elu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/alexnet_elu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9780\tvalidation acc 0.4740\ttest acc 0.4920\n",
      "beta = 0.8:\ttrain acc 0.6800\tvalidation acc 0.5100\ttest acc 0.5320\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.5977\tvalidation acc 0.3620\ttest acc 0.4081\n",
      "beta = 0.8:\ttrain acc 0.6185\tvalidation acc 0.4840\ttest acc 0.4967\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.5741\tvalidation acc 0.3320\ttest acc 0.3587\n",
      "beta = 0.8:\ttrain acc 0.5513\tvalidation acc 0.4200\ttest acc 0.4614\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.6030\tvalidation acc 0.3300\ttest acc 0.3622\n",
      "beta = 1.0:\ttrain acc 0.6021\tvalidation acc 0.4440\ttest acc 0.4616\n"
     ]
    }
   ],
   "source": [
    "# mlp1 elu\n",
    "from dl_spectral_normalization.models import mlp as model\n",
    "arch = model.mlp1_elu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_mlp1_elu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/mlp1_elu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname, opt='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9901\tvalidation acc 0.4620\ttest acc 0.5080\n",
      "beta = 1.0:\ttrain acc 0.7938\tvalidation acc 0.5300\ttest acc 0.5587\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.8735\tvalidation acc 0.3140\ttest acc 0.3523\n",
      "beta = 1.0:\ttrain acc 0.7272\tvalidation acc 0.4740\ttest acc 0.5200\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9341\tvalidation acc 0.3300\ttest acc 0.3499\n",
      "beta = 1.0:\ttrain acc 0.6561\tvalidation acc 0.4540\ttest acc 0.4835\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.5721\tvalidation acc 0.3320\ttest acc 0.3581\n",
      "beta = 1.0:\ttrain acc 0.6611\tvalidation acc 0.4600\ttest acc 0.4876\n"
     ]
    }
   ],
   "source": [
    "# mlp2 elu\n",
    "from dl_spectral_normalization.models import mlp as model\n",
    "arch = model.mlp2_elu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_mlp2_elu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/mlp2_elu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname, opt='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.8440\ttest acc 0.8541\n",
      "beta = 1.6:\ttrain acc 1.0000\tvalidation acc 0.8720\ttest acc 0.8601\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.6520\ttest acc 0.6577\n",
      "beta = 1.6:\ttrain acc 1.0000\tvalidation acc 0.6780\ttest acc 0.6718\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9887\tvalidation acc 0.5180\ttest acc 0.5266\n",
      "beta = 1.6:\ttrain acc 1.0000\tvalidation acc 0.5840\ttest acc 0.5781\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.1000\tvalidation acc 0.1140\ttest acc 0.0993\n",
      "beta = 1.0:\ttrain acc 0.6862\tvalidation acc 0.6180\ttest acc 0.6225\n"
     ]
    }
   ],
   "source": [
    "# Inception\n",
    "from dl_spectral_normalization.models import inception as model\n",
    "arch = model.inception_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_inception.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/inception/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.5600\ttest acc 0.5693\n",
      "beta = 1.0:\ttrain acc 0.6363\tvalidation acc 0.5680\ttest acc 0.5673\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9811\tvalidation acc 0.5200\ttest acc 0.4775\n",
      "beta = 1.0:\ttrain acc 0.6217\tvalidation acc 0.5580\ttest acc 0.5551\n"
     ]
    }
   ],
   "source": [
    "# Inception norm-inf attacks (eps=0.1)\n",
    "from dl_spectral_normalization.models import inception as model\n",
    "attacks_dict_orderinf = {\n",
    "    'fgm': 0.1,\n",
    "    'pgm': 0.1\n",
    "}\n",
    "arch = model.inception_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_inception_orderinf_eps0.1.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/inception_norminfattacks_eps0.1/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict_orderinf, results_file, dirname, order=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.8180\ttest acc 0.8044\n",
      "beta = 1.6:\ttrain acc 1.0000\tvalidation acc 0.8400\ttest acc 0.8267\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.6280\ttest acc 0.6286\n",
      "beta = 1.6:\ttrain acc 1.0000\tvalidation acc 0.6500\ttest acc 0.6563\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9921\tvalidation acc 0.4760\ttest acc 0.4894\n",
      "beta = 2.5:\ttrain acc 1.0000\tvalidation acc 0.5860\ttest acc 0.5456\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.1000\tvalidation acc 0.1140\ttest acc 0.0993\n",
      "beta = 1.0:\ttrain acc 0.8501\tvalidation acc 0.5740\ttest acc 0.5874\n"
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "from dl_spectral_normalization.models import resnet as model\n",
    "arch = model.resnet_sn\n",
    "arch_bn = model.resnet\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_resnet.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/resnet/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9879\tvalidation acc 0.4820\ttest acc 0.4872\n",
      "beta = 1.0:\ttrain acc 0.7015\tvalidation acc 0.5260\ttest acc 0.5153\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9795\tvalidation acc 0.4200\ttest acc 0.4402\n",
      "beta = 1.0:\ttrain acc 0.7153\tvalidation acc 0.5020\ttest acc 0.5278\n"
     ]
    }
   ],
   "source": [
    "# ResNet norm-inf attacks (eps=0.1)\n",
    "from dl_spectral_normalization.models import resnet as model\n",
    "attacks_dict_orderinf = {\n",
    "    'fgm': 0.1,\n",
    "    'pgm': 0.1\n",
    "}\n",
    "arch = model.resnet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_cifar10_resnet_orderinf_eps0.1.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/cifar10/resnet_norminfattacks_eps0.1/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict_orderinf, results_file, dirname, order=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-68ddcc8ce1f5>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "Xtr = mnist.train.images.reshape(-1, 28, 28, 1)\n",
    "Ytr = mnist.train.labels.astype(float)\n",
    "Xtt = mnist.test.images.reshape(-1, 28, 28, 1)\n",
    "Ytt = mnist.test.labels.astype(float)\n",
    "\n",
    "Xva, Yva = Xtt[:500], Ytt[:500]\n",
    "Xtt, Ytt = Xtt[500:], Ytt[500:]\n",
    "C2 = np.mean([np.sqrt(np.sum(np.square(i))) for i in Xtr])\n",
    "gamma = 0.04*C2\n",
    "eps_wrm = 1./(2*gamma)\n",
    "eps = 0.05*C2\n",
    "\n",
    "attacks_dict = {\n",
    "    'erm': 0,\n",
    "    'fgm': eps,\n",
    "    'pgm': eps,\n",
    "    'wrm': eps_wrm\n",
    "}\n",
    "\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/elunet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9809\tvalidation acc 0.9440\ttest acc 0.9469\n",
      "beta = 8.0:\ttrain acc 0.9867\tvalidation acc 0.9560\ttest acc 0.9512\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9803\tvalidation acc 0.9420\ttest acc 0.9471\n",
      "beta = inf:\ttrain acc 0.9803\tvalidation acc 0.9420\ttest acc 0.9471\n"
     ]
    }
   ],
   "source": [
    "# elunet norm-inf attacks (eps=0.1)\n",
    "from dl_spectral_normalization.models import elunet as model\n",
    "attacks_dict_orderinf = {\n",
    "    'fgm': 0.1,\n",
    "    'pgm': 0.1\n",
    "}\n",
    "arch = model.elunet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_elunet_orderinf_eps0.1.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/elunet_norminfattacks_eps0.1/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict_orderinf, results_file, dirname, order=np.inf,\n",
    "                                  load_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9987\tvalidation acc 0.9900\ttest acc 0.9867\n",
      "beta = inf:\ttrain acc 0.9987\tvalidation acc 0.9900\ttest acc 0.9867\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9453\tvalidation acc 0.9020\ttest acc 0.9216\n",
      "beta = 4.0:\ttrain acc 0.9514\tvalidation acc 0.9160\ttest acc 0.9268\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9942\tvalidation acc 0.9660\ttest acc 0.9732\n",
      "beta = 4.0:\ttrain acc 0.9963\tvalidation acc 0.9800\ttest acc 0.9739\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9833\tvalidation acc 0.9560\ttest acc 0.9662\n",
      "beta = 4.0:\ttrain acc 0.9962\tvalidation acc 0.9800\ttest acc 0.9740\n"
     ]
    }
   ],
   "source": [
    "# elunet\n",
    "from dl_spectral_normalization.models import elunet as model\n",
    "arch = model.elunet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_elunet.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/elunet/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname,\n",
    "                                  load_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9417\tvalidation acc 0.9260\ttest acc 0.9266\n",
      "beta = 16.0:\ttrain acc 0.9403\tvalidation acc 0.9320\ttest acc 0.9280\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.6295\tvalidation acc 0.5980\ttest acc 0.6479\n",
      "beta = 1.0:\ttrain acc 0.6819\tvalidation acc 0.6520\ttest acc 0.6977\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.8403\tvalidation acc 0.8220\ttest acc 0.8454\n",
      "beta = 16.0:\ttrain acc 0.8402\tvalidation acc 0.8220\ttest acc 0.8453\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.8425\tvalidation acc 0.8300\ttest acc 0.8464\n",
      "beta = 16.0:\ttrain acc 0.8424\tvalidation acc 0.8300\ttest acc 0.8464\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "from dl_spectral_normalization.models import softmax as model\n",
    "arch = model.softmax_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_softmax.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/softmax/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.9820\ttest acc 0.9813\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.9820\ttest acc 0.9813\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9153\tvalidation acc 0.8220\ttest acc 0.8757\n",
      "beta = 8.0:\ttrain acc 0.9158\tvalidation acc 0.8300\ttest acc 0.8769\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9979\tvalidation acc 0.9560\ttest acc 0.9577\n",
      "beta = 16.0:\ttrain acc 1.0000\tvalidation acc 0.9600\ttest acc 0.9585\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.8817\tvalidation acc 0.8560\ttest acc 0.8762\n",
      "beta = 8.0:\ttrain acc 0.9994\tvalidation acc 0.9580\ttest acc 0.9593\n"
     ]
    }
   ],
   "source": [
    "# mlp1 elu\n",
    "from dl_spectral_normalization.models import mlp as model\n",
    "arch = model.mlp1_elu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_mlp1_elu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/mlp1_elu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9999\tvalidation acc 0.9840\ttest acc 0.9824\n",
      "beta = 8.0:\ttrain acc 1.0000\tvalidation acc 0.9900\ttest acc 0.9837\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9102\tvalidation acc 0.8360\ttest acc 0.8686\n",
      "beta = 8.0:\ttrain acc 0.9274\tvalidation acc 0.8400\ttest acc 0.8708\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9946\tvalidation acc 0.9520\ttest acc 0.9487\n",
      "beta = 4.0:\ttrain acc 0.9993\tvalidation acc 0.9660\ttest acc 0.9596\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.8989\tvalidation acc 0.8800\ttest acc 0.8907\n",
      "beta = 4.0:\ttrain acc 0.9996\tvalidation acc 0.9580\ttest acc 0.9606\n"
     ]
    }
   ],
   "source": [
    "# mlp1 relu\n",
    "from dl_spectral_normalization.models import mlp as model\n",
    "arch = model.mlp1_relu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_mlp1_relu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/mlp1_relu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9987\tvalidation acc 0.9760\ttest acc 0.9805\n",
      "beta = 2.0:\ttrain acc 0.9994\tvalidation acc 0.9840\ttest acc 0.9821\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9715\tvalidation acc 0.8340\ttest acc 0.8808\n",
      "beta = 16.0:\ttrain acc 0.9840\tvalidation acc 0.8780\ttest acc 0.8995\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9984\tvalidation acc 0.9640\ttest acc 0.9628\n",
      "beta = 4.0:\ttrain acc 1.0000\tvalidation acc 0.9700\ttest acc 0.9675\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9688\tvalidation acc 0.8940\ttest acc 0.9136\n",
      "beta = 8.0:\ttrain acc 0.9991\tvalidation acc 0.9720\ttest acc 0.9645\n"
     ]
    }
   ],
   "source": [
    "# mlp2 elu\n",
    "from dl_spectral_normalization.models import mlp as model\n",
    "arch = model.mlp2_elu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_mlp2_elu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/mlp2_elu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 0.9989\tvalidation acc 0.9760\ttest acc 0.9808\n",
      "beta = 16.0:\ttrain acc 1.0000\tvalidation acc 0.9860\ttest acc 0.9845\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9751\tvalidation acc 0.8420\ttest acc 0.8835\n",
      "beta = 4.0:\ttrain acc 0.9925\tvalidation acc 0.8940\ttest acc 0.9091\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9981\tvalidation acc 0.9460\ttest acc 0.9595\n",
      "beta = 4.0:\ttrain acc 1.0000\tvalidation acc 0.9740\ttest acc 0.9698\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9545\tvalidation acc 0.8860\ttest acc 0.9043\n",
      "beta = 2.0:\ttrain acc 0.9990\tvalidation acc 0.9800\ttest acc 0.9717\n"
     ]
    }
   ],
   "source": [
    "# mlp2 relu\n",
    "from dl_spectral_normalization.models import mlp as model\n",
    "arch = model.mlp2_relu_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_mnist_mlp2_relu.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/mnist/mlp2_relu/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_cifar10 import get_svhn_dataset\n",
    "\n",
    "Xtr, Ytr, Xtt, Ytt = get_svhn_dataset(0)\n",
    "Xva, Yva = Xtt[:500], Ytt[:500]\n",
    "Xtt, Ytt = Xtt[500:], Ytt[500:]\n",
    "C2 = np.mean([np.sqrt(np.sum(np.square(i))) for i in Xtr])\n",
    "gamma = 0.002*C2\n",
    "eps_wrm = 1./(2*gamma)\n",
    "eps = 0.05*C2\n",
    "\n",
    "attacks_dict = {\n",
    "    'erm': 0,\n",
    "    'fgm': eps,\n",
    "    'pgm': eps,\n",
    "    'wrm': eps_wrm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERM training\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.9220\ttest acc 0.9295\n",
      "beta = inf:\ttrain acc 1.0000\tvalidation acc 0.9220\ttest acc 0.9295\n",
      "WRM training\n",
      "beta = inf:\ttrain acc 0.9993\tvalidation acc 0.8060\ttest acc 0.8295\n",
      "beta = 1.3:\ttrain acc 0.8722\tvalidation acc 0.8300\ttest acc 0.8403\n",
      "PGM training\n",
      "beta = inf:\ttrain acc 0.9992\tvalidation acc 0.7700\ttest acc 0.7798\n",
      "beta = 1.3:\ttrain acc 0.8453\tvalidation acc 0.8160\ttest acc 0.8126\n",
      "FGM training\n",
      "beta = inf:\ttrain acc 0.9660\tvalidation acc 0.7420\ttest acc 0.7648\n",
      "beta = 1.6:\ttrain acc 0.9506\tvalidation acc 0.8380\ttest acc 0.8311\n"
     ]
    }
   ],
   "source": [
    "# AlexNet\n",
    "from dl_spectral_normalization.models import alexnet as model\n",
    "arch = model.alexnet_sn\n",
    "results_file = '/data/save_weights_tf1.10.1/results/table_results_svhn_alexnet.pickle'\n",
    "dirname = '/data/save_weights_tf1.10.1/svhn/alexnet/'\n",
    "table_results = get_table_results(Xtr, Ytr, Xva, Yva, Xtt, Ytt, arch,\n",
    "                                  attacks_dict, results_file, dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_results_cifar10_alexnet.pickle\n",
      "table_results_cifar10_alexnet_elu.pickle\n",
      "table_results_cifar10_alexnet_orderinf_eps0.1.pickle\n",
      "table_results_cifar10_alexnet_orderinf_eps0.3.pickle\n",
      "table_results_cifar10_inception.pickle\n",
      "table_results_cifar10_inception_orderinf_eps0.1.pickle\n",
      "table_results_cifar10_mlp1_elu.pickle\n",
      "table_results_cifar10_mlp2_elu.pickle\n",
      "table_results_cifar10_resnet.pickle\n",
      "table_results_cifar10_resnet_orderinf_eps0.1.pickle\n",
      "table_results_cifar10_softmax.pickle\n",
      "table_results_mnist_elunet.pickle\n",
      "table_results_mnist_elunet_orderinf_eps0.1.pickle\n",
      "table_results_mnist_mlp1_elu.pickle\n",
      "table_results_mnist_mlp1_relu.pickle\n",
      "table_results_mnist_mlp2_elu.pickle\n",
      "table_results_mnist_mlp2_relu.pickle\n",
      "table_results_mnist_softmax.pickle\n",
      "table_results_svhn_alexnet.pickle\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    'Dataset',\n",
    "    'Architecture',\n",
    "    'Training',\n",
    "    'Train acc',\n",
    "    'Test acc',\n",
    "    'Train acc (SN)',\n",
    "    'Test acc (SN)',\n",
    "    'Beta'\n",
    "]\n",
    "\n",
    "# Dataset, architecture, training combinations to ignore\n",
    "ignore_combinations = {\n",
    "    ('cifar10', 'resnet', 'fgm'),\n",
    "    ('cifar10', 'inception', 'fgm'),\n",
    "    ('mnist', 'mlp2_relu', 'erm'),\n",
    "    ('mnist', 'mlp2_relu', 'fgm'),\n",
    "    ('mnist', 'mlp2_relu', 'pgm'),\n",
    "    ('mnist', 'mlp2_relu', 'wrm'),\n",
    "    ('mnist', 'mlp1_relu', 'erm'),\n",
    "    ('mnist', 'mlp1_relu', 'fgm'),\n",
    "    ('mnist', 'mlp1_relu', 'pgm'),\n",
    "    ('mnist', 'mlp1_relu', 'wrm'),\n",
    "    ('cifar10', 'softmax', 'erm'),\n",
    "    ('cifar10', 'softmax', 'fgm'),\n",
    "    ('cifar10', 'softmax', 'pgm'),\n",
    "    ('cifar10', 'softmax', 'wrm'),\n",
    "    ('mnist', 'softmax', 'erm'),\n",
    "    ('mnist', 'softmax', 'fgm'),\n",
    "    ('mnist', 'softmax', 'pgm'),\n",
    "    ('mnist', 'softmax', 'wrm'),\n",
    "    ('mnist', 'elunet_orderinf_eps0.1', 'fgm'),\n",
    "    ('mnist', 'elunet_orderinf_eps0.1', 'pgm'),\n",
    "    ('cifar10', 'alexnet_orderinf_eps0.3', 'fgm'),\n",
    "    ('cifar10', 'alexnet_orderinf_eps0.3', 'pgm'),\n",
    "    ('cifar10', 'inception_orderinf_eps0.1', 'fgm'),\n",
    "    ('cifar10', 'resnet_orderinf_eps0.1', 'fgm')\n",
    "}\n",
    "\n",
    "table = {col:[] for col in cols}\n",
    "\n",
    "results_dir = '/data/save_weights_tf1.10.1/results/'\n",
    "for f in sorted(os.listdir(results_dir)):\n",
    "    if 'table_results' in f:\n",
    "        print(f)\n",
    "        \n",
    "        results_file = os.path.join(results_dir, f)\n",
    "        table_results = pickle.load(file(results_file, 'rb'))\n",
    "        \n",
    "        dataset = f.split('_')[2]\n",
    "        architecture = f.split(dataset+'_')[1].split('.pickle')[0]\n",
    "        \n",
    "        for training in ['erm', 'fgm', 'pgm', 'wrm']:\n",
    "            if (dataset, architecture, training) not in ignore_combinations and training in table_results:\n",
    "                tr_accs, va_accs, tt_accs = table_results[training]\n",
    "                best_beta = print_best_beta(tr_accs, va_accs, tt_accs, printinf=False, return_beta=True)\n",
    "                \n",
    "                table['Dataset'].append(dataset)\n",
    "                table['Architecture'].append(architecture)\n",
    "                table['Training'].append(training)\n",
    "                table['Train acc'].append(table_results[training][0][np.inf])\n",
    "                table['Test acc'].append(table_results[training][2][np.inf])\n",
    "                table['Train acc (SN)'].append(table_results[training][0][best_beta])\n",
    "                table['Test acc (SN)'].append(table_results[training][2][best_beta])\n",
    "                table['Beta'].append(best_beta)\n",
    "            \n",
    "tabledf = pd.DataFrame.from_dict(table)[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some formatting stuff\n",
    "tabledf['Dataset'] = map(lambda x: x.upper(), tabledf['Dataset'])\n",
    "tabledf['Training'] = map(lambda x: x.upper(), tabledf['Training'])\n",
    "tabledf.loc[tabledf['Architecture'] == 'alexnet', 'Architecture'] = 'AlexNet'\n",
    "tabledf.loc[tabledf['Architecture'] == 'alexnet_elu', 'Architecture'] = 'ELU-AlexNet'\n",
    "tabledf.loc[tabledf['Architecture'] == 'inception', 'Architecture'] = 'Inception'\n",
    "tabledf.loc[tabledf['Architecture'] == 'resnet', 'Architecture'] = 'ResNet'\n",
    "tabledf.loc[tabledf['Architecture'] == 'mlp1_elu', 'Architecture'] = '1-layer MLP'\n",
    "tabledf.loc[tabledf['Architecture'] == 'mlp2_elu', 'Architecture'] = '2-layer MLP'\n",
    "tabledf.loc[tabledf['Architecture'] == 'elunet', 'Architecture'] = 'ELU-Net'\n",
    "tabledf.loc[tabledf['Architecture'] == 'softmax', 'Architecture'] = 'Softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Training</th>\n",
       "      <th>Train acc</th>\n",
       "      <th>Test acc</th>\n",
       "      <th>Train acc (SN)</th>\n",
       "      <th>Test acc (SN)</th>\n",
       "      <th>Beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>WRM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ELU-AlexNet</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ELU-AlexNet</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ELU-AlexNet</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ELU-AlexNet</td>\n",
       "      <td>WRM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>alexnet_orderinf_eps0.1</td>\n",
       "      <td>FGM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>alexnet_orderinf_eps0.1</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>Inception</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>Inception</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>Inception</td>\n",
       "      <td>WRM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>inception_orderinf_eps0.1</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>ERM</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>WRM</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>ERM</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>WRM</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>WRM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CIFAR10</td>\n",
       "      <td>resnet_orderinf_eps0.1</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>ELU-Net</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>ELU-Net</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>ELU-Net</td>\n",
       "      <td>PGM</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>ELU-Net</td>\n",
       "      <td>WRM</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>PGM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>1-layer MLP</td>\n",
       "      <td>WRM</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>PGM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MNIST</td>\n",
       "      <td>2-layer MLP</td>\n",
       "      <td>WRM</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>ERM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>FGM</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>PGM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVHN</td>\n",
       "      <td>AlexNet</td>\n",
       "      <td>WRM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset               Architecture Training  Train acc  Test acc  \\\n",
       "0   CIFAR10                    AlexNet      ERM       1.00      0.79   \n",
       "1   CIFAR10                    AlexNet      FGM       0.98      0.54   \n",
       "2   CIFAR10                    AlexNet      PGM       0.99      0.50   \n",
       "3   CIFAR10                    AlexNet      WRM       1.00      0.61   \n",
       "4   CIFAR10                ELU-AlexNet      ERM       1.00      0.79   \n",
       "5   CIFAR10                ELU-AlexNet      FGM       0.97      0.52   \n",
       "6   CIFAR10                ELU-AlexNet      PGM       0.98      0.53   \n",
       "7   CIFAR10                ELU-AlexNet      WRM       1.00      0.60   \n",
       "8   CIFAR10    alexnet_orderinf_eps0.1      FGM       1.00      0.51   \n",
       "9   CIFAR10    alexnet_orderinf_eps0.1      PGM       0.99      0.44   \n",
       "10  CIFAR10                  Inception      ERM       1.00      0.85   \n",
       "11  CIFAR10                  Inception      PGM       0.99      0.53   \n",
       "12  CIFAR10                  Inception      WRM       1.00      0.66   \n",
       "13  CIFAR10  inception_orderinf_eps0.1      PGM       0.98      0.48   \n",
       "14  CIFAR10                1-layer MLP      ERM       0.98      0.49   \n",
       "15  CIFAR10                1-layer MLP      FGM       0.60      0.36   \n",
       "16  CIFAR10                1-layer MLP      PGM       0.57      0.36   \n",
       "17  CIFAR10                1-layer MLP      WRM       0.60      0.41   \n",
       "18  CIFAR10                2-layer MLP      ERM       0.99      0.51   \n",
       "19  CIFAR10                2-layer MLP      FGM       0.57      0.36   \n",
       "20  CIFAR10                2-layer MLP      PGM       0.93      0.35   \n",
       "21  CIFAR10                2-layer MLP      WRM       0.87      0.35   \n",
       "22  CIFAR10                     ResNet      ERM       1.00      0.80   \n",
       "23  CIFAR10                     ResNet      PGM       0.99      0.49   \n",
       "24  CIFAR10                     ResNet      WRM       1.00      0.63   \n",
       "25  CIFAR10     resnet_orderinf_eps0.1      PGM       0.98      0.44   \n",
       "26    MNIST                    ELU-Net      ERM       1.00      0.99   \n",
       "27    MNIST                    ELU-Net      FGM       0.98      0.97   \n",
       "28    MNIST                    ELU-Net      PGM       0.99      0.97   \n",
       "29    MNIST                    ELU-Net      WRM       0.95      0.92   \n",
       "30    MNIST                1-layer MLP      ERM       1.00      0.98   \n",
       "31    MNIST                1-layer MLP      FGM       0.88      0.88   \n",
       "32    MNIST                1-layer MLP      PGM       1.00      0.96   \n",
       "33    MNIST                1-layer MLP      WRM       0.92      0.88   \n",
       "34    MNIST                2-layer MLP      ERM       1.00      0.98   \n",
       "35    MNIST                2-layer MLP      FGM       0.97      0.91   \n",
       "36    MNIST                2-layer MLP      PGM       1.00      0.96   \n",
       "37    MNIST                2-layer MLP      WRM       0.97      0.88   \n",
       "38     SVHN                    AlexNet      ERM       1.00      0.93   \n",
       "39     SVHN                    AlexNet      FGM       0.97      0.76   \n",
       "40     SVHN                    AlexNet      PGM       1.00      0.78   \n",
       "41     SVHN                    AlexNet      WRM       1.00      0.83   \n",
       "\n",
       "    Train acc (SN)  Test acc (SN)       Beta  \n",
       "0             1.00           0.79   2.000000  \n",
       "1             0.93           0.63   1.600000  \n",
       "2             0.92           0.62   1.600000  \n",
       "3             0.76           0.65   1.300000  \n",
       "4             1.00           0.79   2.000000  \n",
       "5             0.68           0.60   1.300000  \n",
       "6             0.88           0.61   1.600000  \n",
       "7             1.00           0.60   4.000000  \n",
       "8             0.67           0.56   1.300000  \n",
       "9             0.86           0.54   1.600000  \n",
       "10            1.00           0.86   1.600000  \n",
       "11            1.00           0.58   1.600000  \n",
       "12            1.00           0.67   1.600000  \n",
       "13            0.62           0.56   1.000000  \n",
       "14            0.68           0.53   0.800000  \n",
       "15            0.60           0.46   1.000000  \n",
       "16            0.55           0.46   0.800000  \n",
       "17            0.62           0.50   0.800000  \n",
       "18            0.79           0.56   1.000000  \n",
       "19            0.66           0.49   1.000000  \n",
       "20            0.66           0.48   1.000000  \n",
       "21            0.73           0.52   1.000000  \n",
       "22            1.00           0.83   1.600000  \n",
       "23            1.00           0.55   2.500000  \n",
       "24            1.00           0.66   1.600000  \n",
       "25            0.72           0.53   1.000000  \n",
       "26            1.00           0.99        inf  \n",
       "27            1.00           0.97   4.000000  \n",
       "28            1.00           0.97   4.000000  \n",
       "29            0.95           0.93   4.000000  \n",
       "30            1.00           0.98        inf  \n",
       "31            1.00           0.96   8.000000  \n",
       "32            1.00           0.96  16.000000  \n",
       "33            0.92           0.88   8.000000  \n",
       "34            1.00           0.98   2.000000  \n",
       "35            1.00           0.96   8.000000  \n",
       "36            1.00           0.97   4.000000  \n",
       "37            0.98           0.90  16.000000  \n",
       "38            1.00           0.93        inf  \n",
       "39            0.95           0.83   1.600000  \n",
       "40            0.85           0.81   1.300000  \n",
       "41            0.87           0.84   1.300000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tabledf.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save table to file\n",
    "tabledf.to_csv(os.path.join(results_dir, 'table.txt'), sep=' ', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      " Dataset &               Architecture & Training &  Train acc &  Test acc &  Train acc (SN) &  Test acc (SN) \\\\\n",
      "\\midrule\n",
      " CIFAR10 &                    AlexNet &      ERM &       1.00 &      0.79 &            1.00 &           0.79 \\\\\n",
      " CIFAR10 &                    AlexNet &      FGM &       0.98 &      0.54 &            0.93 &           0.63 \\\\\n",
      " CIFAR10 &                    AlexNet &      PGM &       0.99 &      0.50 &            0.92 &           0.62 \\\\\n",
      " CIFAR10 &                    AlexNet &      WRM &       1.00 &      0.61 &            0.76 &           0.65 \\\\\n",
      " CIFAR10 &                ELU-AlexNet &      ERM &       1.00 &      0.79 &            1.00 &           0.79 \\\\\n",
      " CIFAR10 &                ELU-AlexNet &      FGM &       0.97 &      0.52 &            0.68 &           0.60 \\\\\n",
      " CIFAR10 &                ELU-AlexNet &      PGM &       0.98 &      0.53 &            0.88 &           0.61 \\\\\n",
      " CIFAR10 &                ELU-AlexNet &      WRM &       1.00 &      0.60 &            1.00 &           0.60 \\\\\n",
      " CIFAR10 &    alexnet\\_orderinf\\_eps0.1 &      FGM &       1.00 &      0.51 &            0.67 &           0.56 \\\\\n",
      " CIFAR10 &    alexnet\\_orderinf\\_eps0.1 &      PGM &       0.99 &      0.44 &            0.86 &           0.54 \\\\\n",
      " CIFAR10 &                  Inception &      ERM &       1.00 &      0.85 &            1.00 &           0.86 \\\\\n",
      " CIFAR10 &                  Inception &      PGM &       0.99 &      0.53 &            1.00 &           0.58 \\\\\n",
      " CIFAR10 &                  Inception &      WRM &       1.00 &      0.66 &            1.00 &           0.67 \\\\\n",
      " CIFAR10 &  inception\\_orderinf\\_eps0.1 &      PGM &       0.98 &      0.48 &            0.62 &           0.56 \\\\\n",
      " CIFAR10 &                1-layer MLP &      ERM &       0.98 &      0.49 &            0.68 &           0.53 \\\\\n",
      " CIFAR10 &                1-layer MLP &      FGM &       0.60 &      0.36 &            0.60 &           0.46 \\\\\n",
      " CIFAR10 &                1-layer MLP &      PGM &       0.57 &      0.36 &            0.55 &           0.46 \\\\\n",
      " CIFAR10 &                1-layer MLP &      WRM &       0.60 &      0.41 &            0.62 &           0.50 \\\\\n",
      " CIFAR10 &                2-layer MLP &      ERM &       0.99 &      0.51 &            0.79 &           0.56 \\\\\n",
      " CIFAR10 &                2-layer MLP &      FGM &       0.57 &      0.36 &            0.66 &           0.49 \\\\\n",
      " CIFAR10 &                2-layer MLP &      PGM &       0.93 &      0.35 &            0.66 &           0.48 \\\\\n",
      " CIFAR10 &                2-layer MLP &      WRM &       0.87 &      0.35 &            0.73 &           0.52 \\\\\n",
      " CIFAR10 &                     ResNet &      ERM &       1.00 &      0.80 &            1.00 &           0.83 \\\\\n",
      " CIFAR10 &                     ResNet &      PGM &       0.99 &      0.49 &            1.00 &           0.55 \\\\\n",
      " CIFAR10 &                     ResNet &      WRM &       1.00 &      0.63 &            1.00 &           0.66 \\\\\n",
      " CIFAR10 &     resnet\\_orderinf\\_eps0.1 &      PGM &       0.98 &      0.44 &            0.72 &           0.53 \\\\\n",
      "   MNIST &                    ELU-Net &      ERM &       1.00 &      0.99 &            1.00 &           0.99 \\\\\n",
      "   MNIST &                    ELU-Net &      FGM &       0.98 &      0.97 &            1.00 &           0.97 \\\\\n",
      "   MNIST &                    ELU-Net &      PGM &       0.99 &      0.97 &            1.00 &           0.97 \\\\\n",
      "   MNIST &                    ELU-Net &      WRM &       0.95 &      0.92 &            0.95 &           0.93 \\\\\n",
      "   MNIST &                1-layer MLP &      ERM &       1.00 &      0.98 &            1.00 &           0.98 \\\\\n",
      "   MNIST &                1-layer MLP &      FGM &       0.88 &      0.88 &            1.00 &           0.96 \\\\\n",
      "   MNIST &                1-layer MLP &      PGM &       1.00 &      0.96 &            1.00 &           0.96 \\\\\n",
      "   MNIST &                1-layer MLP &      WRM &       0.92 &      0.88 &            0.92 &           0.88 \\\\\n",
      "   MNIST &                2-layer MLP &      ERM &       1.00 &      0.98 &            1.00 &           0.98 \\\\\n",
      "   MNIST &                2-layer MLP &      FGM &       0.97 &      0.91 &            1.00 &           0.96 \\\\\n",
      "   MNIST &                2-layer MLP &      PGM &       1.00 &      0.96 &            1.00 &           0.97 \\\\\n",
      "   MNIST &                2-layer MLP &      WRM &       0.97 &      0.88 &            0.98 &           0.90 \\\\\n",
      "    SVHN &                    AlexNet &      ERM &       1.00 &      0.93 &            1.00 &           0.93 \\\\\n",
      "    SVHN &                    AlexNet &      FGM &       0.97 &      0.76 &            0.95 &           0.83 \\\\\n",
      "    SVHN &                    AlexNet &      PGM &       1.00 &      0.78 &            0.85 &           0.81 \\\\\n",
      "    SVHN &                    AlexNet &      WRM &       1.00 &      0.83 &            0.87 &           0.84 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print latex for table\n",
    "print(tabledf.round(2).drop(['Beta'], axis=1).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x201.6 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = ['s', 'o', 'v', 'D', '+', '.', '^', '*']\n",
    "plt.figure(figsize=(10, 2.8))\n",
    "for i, adv in enumerate(['ERM', 'FGM', 'PGM', 'WRM']):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.plot([0, 1], [0, 1], lw=0.3, c='k')\n",
    "    for j, dataset in enumerate(['CIFAR10', 'MNIST', 'SVHN']):\n",
    "        rows = tabledf.loc[(tabledf['Training'] == adv) & (tabledf['Dataset'] == dataset)]\n",
    "        plt.scatter(rows['Test acc'], rows['Test acc (SN)'], label=dataset,\n",
    "                    marker=markers[j], edgecolor='k')\n",
    "    plt.xlabel('Test acc without SN')\n",
    "    if i == 0:\n",
    "        plt.ylabel('Test acc with SN')\n",
    "    plt.title('%s training'%(adv.upper()))\n",
    "    if i == 3:\n",
    "        plt.legend(loc=4)\n",
    "    plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/data/Figures/table_scatterplots.pdf', format='pdf', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
